{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Apurva3509/Applied-Machine-Learning/blob/main/5/AML_HW5_Questions_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9bcdbd2-3401-41ad-a83f-830e9346e607",
      "metadata": {
        "id": "d9bcdbd2-3401-41ad-a83f-830e9346e607"
      },
      "source": [
        "# **Applied Machine Learning Homework 5: NLP**\n",
        "**Due April 29,2024 (Monday) 11:59PM EST**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions\n",
        "\n",
        "1) Please push the .ipynb and .pdf to Github Classroom prior to the deadline, .py file is optional (not needed).<br>\n",
        "2) Please include your Name and UNI below."
      ],
      "metadata": {
        "id": "EyLMOVXq-bBX"
      },
      "id": "EyLMOVXq-bBX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Name:  Apurva Patel\n",
        "##UNI: amp2365"
      ],
      "metadata": {
        "id": "leint4ja8V77"
      },
      "id": "leint4ja8V77"
    },
    {
      "cell_type": "markdown",
      "id": "70df26be-5638-4b0d-a252-4437eb76aa46",
      "metadata": {
        "id": "70df26be-5638-4b0d-a252-4437eb76aa46"
      },
      "source": [
        "### Natural Language Processing\n",
        "We will train a supervised training model to predict if a tweet has a positive or negative sentiment."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e0d9a19-25ea-4490-b0e8-7909bcdc3d9d",
      "metadata": {
        "id": "2e0d9a19-25ea-4490-b0e8-7909bcdc3d9d"
      },
      "source": [
        "####  **Dataset loading & dev/test splits**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fafa37c4-c8fc-4697-9bbe-11539d710bf7",
      "metadata": {
        "id": "fafa37c4-c8fc-4697-9bbe-11539d710bf7"
      },
      "source": [
        "**1.1) Load the twitter dataset from NLTK library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5f4ce405-237b-42d2-9c81-25ff28deaf4a",
      "metadata": {
        "id": "5f4ce405-237b-42d2-9c81-25ff28deaf4a",
        "outputId": "5aec2144-89a5-4668-fc73-050bf95342c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('twitter_samples')\n",
        "from nltk.corpus import twitter_samples\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "import pandas as pd\n",
        "import string\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "# Feel free to import any other packages you need"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c41d62ce-3c78-4b6c-9238-111d990d170f",
      "metadata": {
        "id": "c41d62ce-3c78-4b6c-9238-111d990d170f"
      },
      "source": [
        "**1.2) Load the positive & negative tweets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b92fb408-f72a-4c23-acd8-7c944a52edd3",
      "metadata": {
        "id": "b92fb408-f72a-4c23-acd8-7c944a52edd3"
      },
      "outputs": [],
      "source": [
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.3) Make a data frame that has all tweets and their corresponding labels**"
      ],
      "metadata": {
        "id": "Vy1K6hxAjfbi"
      },
      "id": "Vy1K6hxAjfbi"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6611bdc8",
      "metadata": {
        "id": "6611bdc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69ad16b6-e34e-47ce-cea4-70524503289b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               tweet  label\n",
            "0  #FollowFriday @France_Inte @PKuchly57 @Milipol...      1\n",
            "1  @Lamb2ja Hey James! How odd :/ Please call our...      1\n",
            "2  @DespiteOfficial we had a listen last night :)...      1\n",
            "3                               @97sides CONGRATS :)      1\n",
            "4  yeaaaah yippppy!!!  my accnt verified rqst has...      1\n"
          ]
        }
      ],
      "source": [
        "# Your Code Here\n",
        "\n",
        "positive_tweets_df = pd.DataFrame({'tweet': all_positive_tweets, 'label': 1})\n",
        "negative_tweets_df = pd.DataFrame({'tweet': all_negative_tweets, 'label': 0})\n",
        "\n",
        "# combine the 2 DF\n",
        "all_tweets_df = pd.concat([positive_tweets_df, negative_tweets_df], ignore_index=True)\n",
        "print(all_tweets_df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.4) Look at the class distribution of the tweets**"
      ],
      "metadata": {
        "id": "xisDSGVanceN"
      },
      "id": "xisDSGVanceN"
    },
    {
      "cell_type": "code",
      "source": [
        "# Your Code Here\n",
        "\n",
        "class_distribution = all_tweets_df['label'].value_counts()\n",
        "print(class_distribution)"
      ],
      "metadata": {
        "id": "xv8oL2_gnYra",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3931cddb-f123-43ff-f697-70fdfc5ee8f0"
      },
      "id": "xv8oL2_gnYra",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "1    5000\n",
            "0    5000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12eae071-fd8a-4a46-9958-0525c635fd88",
      "metadata": {
        "id": "12eae071-fd8a-4a46-9958-0525c635fd88"
      },
      "source": [
        "**1.5) Create a development & test split (80/20 ratio):**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0f3673db-d7a8-470b-a3d3-f4522cd359b8",
      "metadata": {
        "id": "0f3673db-d7a8-470b-a3d3-f4522cd359b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4c00280-7529-4076-8aea-f18bd2ece9c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Development set shape: (8000, 2)\n",
            "Test set shape: (2000, 2)\n"
          ]
        }
      ],
      "source": [
        "# Your Code Here\n",
        "\n",
        "dev_set, test_set = train_test_split(all_tweets_df, test_size=0.2, random_state=42)\n",
        "print(\"Development set shape:\", dev_set.shape)\n",
        "print(\"Test set shape:\", test_set.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32b23398-e80e-4624-b89e-c02fabfd3f8d",
      "metadata": {
        "id": "32b23398-e80e-4624-b89e-c02fabfd3f8d"
      },
      "source": [
        "#### **Data preprocessing**\n",
        "We will do some data preprocessing before we tokenize the data. We will remove `#` symbol, hyperlinks, stop words & punctuations from the data. You can use the `re` package in python to find and replace these strings."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f89d9d69-1640-4583-a7b7-7ec04ccf3310",
      "metadata": {
        "id": "f89d9d69-1640-4583-a7b7-7ec04ccf3310"
      },
      "source": [
        "**1.6) Replace the `#` symbol with '' in every tweet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5db4dd6d-e775-49d3-96e1-57620c042d46",
      "metadata": {
        "id": "5db4dd6d-e775-49d3-96e1-57620c042d46"
      },
      "outputs": [],
      "source": [
        "# Your Code Here\n",
        "dev_set['tweet'] = dev_set['tweet'].apply(lambda x: x.replace('#', ''))\n",
        "test_set['tweet'] = test_set['tweet'].apply(lambda x: x.replace('#', ''))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24c4caa8-d71d-46a8-8859-a8e85c56acfe",
      "metadata": {
        "id": "24c4caa8-d71d-46a8-8859-a8e85c56acfe"
      },
      "source": [
        "**1.7) Replace hyperlinks with '' in every tweet**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Your Code Here\n",
        "dev_set['tweet'] = dev_set['tweet'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
        "test_set['tweet'] = test_set['tweet'].apply(lambda x: re.sub(r'http\\S+', '', x))"
      ],
      "metadata": {
        "id": "I20m5bIZqp9S"
      },
      "id": "I20m5bIZqp9S",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "492ae463-b611-4292-9ad2-b778856bf8bc",
      "metadata": {
        "id": "492ae463-b611-4292-9ad2-b778856bf8bc"
      },
      "source": [
        "**1.8) Remove all stop words**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Your Code Here\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "dev_set['tweet'] = dev_set['tweet'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stop_words]))\n",
        "test_set['tweet'] = test_set['tweet'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stop_words]))"
      ],
      "metadata": {
        "id": "HA-1Qs8Vz4mB"
      },
      "id": "HA-1Qs8Vz4mB",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "169bf8ad-f7ba-4e67-a1a0-92fcdd193ab9",
      "metadata": {
        "id": "169bf8ad-f7ba-4e67-a1a0-92fcdd193ab9"
      },
      "source": [
        "**1.9) Remove all punctuations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "5fbeaccf",
      "metadata": {
        "id": "5fbeaccf"
      },
      "outputs": [],
      "source": [
        "# Your Code Here\n",
        "\n",
        "dev_set['tweet'] = dev_set['tweet'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
        "test_set['tweet'] = test_set['tweet'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2f1af18-0c07-4ffb-994e-daead4740a53",
      "metadata": {
        "id": "b2f1af18-0c07-4ffb-994e-daead4740a53"
      },
      "source": [
        "**1.10) Apply stemming on the development & test datasets using Porter algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Your Code Here\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "dev_set['tweet'] = dev_set['tweet'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))\n",
        "test_set['tweet'] = test_set['tweet'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))"
      ],
      "metadata": {
        "id": "gSPLyHbmxC1q"
      },
      "id": "gSPLyHbmxC1q",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "687e23ef-dafd-4183-b2f1-86089e281dd8",
      "metadata": {
        "id": "687e23ef-dafd-4183-b2f1-86089e281dd8"
      },
      "source": [
        "#### **Model training**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c40fa44-01ad-4788-98b9-9c8f0c1252ef",
      "metadata": {
        "id": "0c40fa44-01ad-4788-98b9-9c8f0c1252ef"
      },
      "source": [
        "**1.11) Create bag of words features for each tweet in the development dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "3d34c009",
      "metadata": {
        "id": "3d34c009"
      },
      "outputs": [],
      "source": [
        "# Your Code Here\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_bow = vectorizer.fit_transform(dev_set['tweet'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4baf65cd-019b-4ff4-b93c-3ca8cfffca8e",
      "metadata": {
        "id": "4baf65cd-019b-4ff4-b93c-3ca8cfffca8e"
      },
      "source": [
        "**1.12) Train a Logistic Regression model on the development dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "3433a6b0-408d-462e-9072-3495b21bc97b",
      "metadata": {
        "id": "3433a6b0-408d-462e-9072-3495b21bc97b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "0c4da8e1-d88f-4412-e475-44328421a451"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Your Code Here\n",
        "\n",
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(X_train_bow, dev_set['label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c16c6f6-7ab2-4d7a-b9dc-098a72381340",
      "metadata": {
        "id": "1c16c6f6-7ab2-4d7a-b9dc-098a72381340"
      },
      "source": [
        "**1.13) Create TF-IDF features for each tweet in the development dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "7b417843-ffc4-4614-b2ef-964f8ec3e510",
      "metadata": {
        "id": "7b417843-ffc4-4614-b2ef-964f8ec3e510"
      },
      "outputs": [],
      "source": [
        "# Your Code Here\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(dev_set['tweet'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea3c9776-aad9-4eda-b3c2-d9f6b3e52427",
      "metadata": {
        "id": "ea3c9776-aad9-4eda-b3c2-d9f6b3e52427"
      },
      "source": [
        "**1.14) Train the Logistic Regression model on the development dataset with TF-IDF features**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "b8c7fe8b-61de-4daa-a338-74295a4902ce",
      "metadata": {
        "id": "b8c7fe8b-61de-4daa-a338-74295a4902ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "a0e97263-fed1-4fb9-bb22-2c295392d381"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Your Code Here\n",
        "\n",
        "lr_model_tfidf = LogisticRegression()\n",
        "lr_model_tfidf.fit(X_train_tfidf, dev_set['label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab0129e7-a0ea-473e-9ad1-667b44a13a92",
      "metadata": {
        "id": "ab0129e7-a0ea-473e-9ad1-667b44a13a92"
      },
      "source": [
        "**1.15) Compare the performance of the two models on the test dataset using a classification report and the scores obtained. Explain the difference in results obtained.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Your Code Here\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# prediction using BoW features\n",
        "X_test_bow = vectorizer.transform(test_set['tweet'])\n",
        "bow_predictions = lr_model.predict(X_test_bow)\n",
        "\n",
        "# prediction using TF-IDF features\n",
        "X_test_tfidf = tfidf_vectorizer.transform(test_set['tweet'])\n",
        "tfidf_predictions = lr_model_tfidf.predict(X_test_tfidf)\n",
        "\n",
        "# classification report for BoW model\n",
        "print(\"Classification Report for Bag of Words model:\")\n",
        "print(classification_report(test_set['label'], bow_predictions))\n",
        "\n",
        "# classification report for TF-IDF model\n",
        "print(\"\\nClassification Report for TF-IDF model:\")\n",
        "print(classification_report(test_set['label'], tfidf_predictions))"
      ],
      "metadata": {
        "id": "C8NwWxJh33G7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ed9804c-43f4-4351-dc16-773f67c16092"
      },
      "id": "C8NwWxJh33G7",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for Bag of Words model:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.80      0.76       988\n",
            "           1       0.78      0.71      0.74      1012\n",
            "\n",
            "    accuracy                           0.75      2000\n",
            "   macro avg       0.76      0.75      0.75      2000\n",
            "weighted avg       0.76      0.75      0.75      2000\n",
            "\n",
            "\n",
            "Classification Report for TF-IDF model:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.78      0.76       988\n",
            "           1       0.78      0.73      0.76      1012\n",
            "\n",
            "    accuracy                           0.76      2000\n",
            "   macro avg       0.76      0.76      0.76      2000\n",
            "weighted avg       0.76      0.76      0.76      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Explanation here\n",
        "\n",
        "Bag of Words (BoW) and TF-IDF models perform well, with similar overall performance metrics.\n",
        "\n",
        "However, the TF-IDF model, which considers the importance of words in the corpus, shows slightly higher accuracy and slightly improved precision, recall, and F1-score compared to the BoW model.\n",
        "\n",
        "This difference is due to TF-IDF's ability to capture more meaningful and discriminative features, resulting in slightly better classification performance on the test dataset.\n",
        "\n",
        "The difference in results between the Bag of Words (BoW) model and the TF-IDF model lies in the way they represent the features of the text data.\n",
        "\n",
        "- BoW simply counts the occurrence of each word in the document, whereas TF-IDF considers the importance of each word in the document relative to the entire corpus.\n",
        "\n",
        "- TF-IDF tends to give higher weights to words that are more unique to the document but less frequent in the corpus, which can result in better performance, especially when dealing with large and diverse datasets.\n"
      ],
      "metadata": {
        "id": "uo7vBVNC-_nK"
      },
      "id": "uo7vBVNC-_nK"
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install texlive texlive-xetex texlive-latex-extra pandoc\n",
        "\n",
        "!pip install pypandoc"
      ],
      "metadata": {
        "id": "J6hfFR-4rPDE"
      },
      "id": "J6hfFR-4rPDE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --to html /content/AML_HW5_Questions_NLP.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJCoFSE8rKJz",
<<<<<<< Updated upstream:5/AML_HW5_Questions_NLP.ipynb
        "outputId": "012ded33-95f7-471f-a250-82186ebcd8bb"
      },
      "id": "CJCoFSE8rKJz",
      "execution_count": 25,
=======
        "outputId": "60e605f1-4ac2-4056-8a4a-c24aa6d53a96"
      },
      "id": "CJCoFSE8rKJz",
      "execution_count": 22,
>>>>>>> Stashed changes:5/AML_HW5_Questions_NLP_amp2365.ipynb
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook /content/AML_HW5_Questions_NLP.ipynb to html\n",
<<<<<<< Updated upstream:5/AML_HW5_Questions_NLP.ipynb
            "[NbConvertApp] Writing 630502 bytes to /content/AML_HW5_Questions_NLP.html\n"
=======
            "[NbConvertApp] Writing 629162 bytes to /content/AML_HW5_Questions_NLP.html\n"
>>>>>>> Stashed changes:5/AML_HW5_Questions_NLP_amp2365.ipynb
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert AML_HW5_Questions_NLP.ipynb --to latex"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_xpd1FPrR5O",
        "outputId": "75924688-a75f-4ddb-9123-961ef10a21fb"
      },
      "id": "M_xpd1FPrR5O",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook AML_HW5_Questions_NLP.ipynb to latex\n",
            "[NbConvertApp] Writing 43472 bytes to AML_HW5_Questions_NLP.tex\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
<<<<<<< Updated upstream:5/AML_HW5_Questions_NLP.ipynb
      "gpuType": "T4",
      "include_colab_link": true
=======
      "gpuType": "T4"
>>>>>>> Stashed changes:5/AML_HW5_Questions_NLP_amp2365.ipynb
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}